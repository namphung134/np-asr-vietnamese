{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vEE86cMWC4G"
      },
      "source": [
        "# **TEST MODEL NP_WHISPER_BASE_VI FOR VIETNAMESE ASR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-B5QhyDhf3s",
        "outputId": "820451d1-00e1-413d-e46c-1402d6d9b7c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hEnvironment setup completed!\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install transformers torch librosa soundfile --quiet\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "\n",
        "print(\"Environment setup completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isKuA2Z6LtRS",
        "outputId": "105355f7-d178-4806-ba86-ce9fd02c831c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading model from: namphungdn134/np-whisper-base-vi\n",
            "Forced decoder IDs for Vietnamese: [(1, 50278), (2, 50359), (3, 50363)]\n",
            "Loading audio from: /content/VISRSG05_A60.wav\n",
            "Input features shape: torch.Size([1, 80, 3000])\n",
            "Generating transcription...\n",
            "ğŸ“ Transcription: tuy lÃ  bÃ  cÅ©ng khÃ´ng cÃ³ cÃ¡i cÆ¡ há»™i Ä‘Æ°á»£c Ä‘i há»c tiáº¿p\n",
            "Predicted IDs: [83, 7493, 3684, 272, 1467, 22747, 11415, 6333, 14830, 269, 9621, 276, 38555, 15832, 13264, 46786, 48667]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import librosa\n",
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
        "\n",
        "# Chá»n thiáº¿t bá»‹ (GPU náº¿u cÃ³)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Táº£i processor vÃ  model\n",
        "model_id = \"namphungdn134/np-whisper-base-vi\"\n",
        "print(f\"Loading model from: {model_id}\")\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_id).to(device)\n",
        "\n",
        "# Cáº¥u hÃ¬nh ngÃ´n ngá»¯ vÃ  task\n",
        "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"vi\", task=\"transcribe\")\n",
        "model.config.forced_decoder_ids = forced_decoder_ids\n",
        "print(f\"Forced decoder IDs for Vietnamese: {forced_decoder_ids}\")\n",
        "\n",
        "# Äá»c file Ã¢m thanh vÃ  chuyá»ƒn vá» dáº¡ng tensor\n",
        "audio_path = \"/content/VISRSG05_A60.wav\"  # Thay báº±ng Ä‘Æ°á»ng dáº«n file cá»§a báº¡n\n",
        "print(f\"Loading audio from: {audio_path}\")\n",
        "audio, sr = librosa.load(audio_path, sr=16000)  # Whisper yÃªu cáº§u 16kHz\n",
        "input_features = processor(audio, sampling_rate=16000, return_tensors=\"pt\").input_features.to(device)\n",
        "print(f\"Input features shape: {input_features.shape}\")\n",
        "\n",
        "# Thá»±c hiá»‡n nháº­n dáº¡ng giá»ng nÃ³i\n",
        "print(\"Generating transcription...\")\n",
        "with torch.no_grad():\n",
        "    predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)\n",
        "\n",
        "# Giáº£i mÃ£ káº¿t quáº£\n",
        "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "print(\"ğŸ“ Transcription:\", transcription)\n",
        "\n",
        "# Debug: In cÃ¡c token Ä‘á»ƒ kiá»ƒm tra\n",
        "print(\"Predicted IDs:\", predicted_ids[0].tolist())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}